{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference Numbers, 2 Targets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Store</th>\n",
       "      <th>Start_of_Week</th>\n",
       "      <th>Week_Date</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Holiday_Name</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2.57</td>\n",
       "      <td>211.0964</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1643690.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>2.55</td>\n",
       "      <td>211.2422</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1641957.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>211.2891</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1611968.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>2.56</td>\n",
       "      <td>211.3196</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1409727.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>2.62</td>\n",
       "      <td>211.3501</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1554806.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID  Store Start_of_Week   Week_Date  Fuel_Price       CPI  \\\n",
       "0           0   0      1    2010-01-30  2010-02-05        2.57  211.0964   \n",
       "1           1   1      1    2010-02-06  2010-02-12        2.55  211.2422   \n",
       "2           2   2      1    2010-02-13  2010-02-19        2.51  211.2891   \n",
       "3           3   3      1    2010-02-20  2010-02-26        2.56  211.3196   \n",
       "4           4   4      1    2010-02-27  2010-03-05        2.62  211.3501   \n",
       "\n",
       "   Unemployment Type    Size  Week  Year  Temperature_C Holiday_Name  \\\n",
       "0         8.106    A  151315     5  2010            6.0   No Holiday   \n",
       "1         8.106    A  151315     6  2010            4.0   No Holiday   \n",
       "2         8.106    A  151315     7  2010            4.0   No Holiday   \n",
       "3         8.106    A  151315     8  2010            8.0   No Holiday   \n",
       "4         8.106    A  151315     9  2010            8.0   No Holiday   \n",
       "\n",
       "   Weekly_Sales  \n",
       "0    1643690.90  \n",
       "1    1641957.44  \n",
       "2    1611968.17  \n",
       "3    1409727.59  \n",
       "4    1554806.68  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart = pd.read_csv('walmartdata.csv')\n",
    "walmart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalave = walmart.groupby([\"Store\"])[\"Weekly_Sales\"].mean()\n",
    "fuelave = walmart.groupby([\"Store\"])[\"Fuel_Price\"].mean()\n",
    "unemave = walmart.groupby([\"Store\"])[\"Unemployment\"].mean()\n",
    "cpiave = walmart.groupby([\"Store\"])[\"CPI\"].mean()\n",
    "tempave = walmart.groupby([\"Store\"])[\"Temperature_C\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Store</th>\n",
       "      <th>Start_of_Week</th>\n",
       "      <th>Week_Date</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Week</th>\n",
       "      <th>Year</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Holiday_Name</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Ave_Sales</th>\n",
       "      <th>Ave_Fuel</th>\n",
       "      <th>Ave_Temp</th>\n",
       "      <th>Ave_Unem</th>\n",
       "      <th>Ave_CPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2.57</td>\n",
       "      <td>211.0964</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>2.55</td>\n",
       "      <td>211.2422</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>211.2891</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>2.56</td>\n",
       "      <td>211.3196</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>2.62</td>\n",
       "      <td>211.3501</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>6434</td>\n",
       "      <td>6434</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-09-22</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>4.00</td>\n",
       "      <td>192.0136</td>\n",
       "      <td>8.684</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>39</td>\n",
       "      <td>2012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>713173.95</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>6435</td>\n",
       "      <td>6435</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-09-29</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>3.98</td>\n",
       "      <td>192.1704</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>40</td>\n",
       "      <td>2012</td>\n",
       "      <td>18.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>733455.07</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>6436</td>\n",
       "      <td>6436</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-06</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>4.00</td>\n",
       "      <td>192.3273</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>41</td>\n",
       "      <td>2012</td>\n",
       "      <td>12.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>734464.36</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>6437</td>\n",
       "      <td>6437</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-13</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>3.97</td>\n",
       "      <td>192.3309</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>42</td>\n",
       "      <td>2012</td>\n",
       "      <td>14.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>718125.53</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>6438</td>\n",
       "      <td>6438</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-20</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>3.88</td>\n",
       "      <td>192.3089</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>43</td>\n",
       "      <td>2012</td>\n",
       "      <td>15.0</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>760281.43</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6439 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    ID  Store Start_of_Week   Week_Date  Fuel_Price       CPI  \\\n",
       "0              0     0      1    2010-01-30  2010-02-05        2.57  211.0964   \n",
       "1              1     1      1    2010-02-06  2010-02-12        2.55  211.2422   \n",
       "2              2     2      1    2010-02-13  2010-02-19        2.51  211.2891   \n",
       "3              3     3      1    2010-02-20  2010-02-26        2.56  211.3196   \n",
       "4              4     4      1    2010-02-27  2010-03-05        2.62  211.3501   \n",
       "...          ...   ...    ...           ...         ...         ...       ...   \n",
       "6434        6434  6434     45    2012-09-22  2012-09-28        4.00  192.0136   \n",
       "6435        6435  6435     45    2012-09-29  2012-10-05        3.98  192.1704   \n",
       "6436        6436  6436     45    2012-10-06  2012-10-12        4.00  192.3273   \n",
       "6437        6437  6437     45    2012-10-13  2012-10-19        3.97  192.3309   \n",
       "6438        6438  6438     45    2012-10-20  2012-10-26        3.88  192.3089   \n",
       "\n",
       "      Unemployment Type    Size  Week  Year  Temperature_C Holiday_Name  \\\n",
       "0            8.106    A  151315     5  2010            6.0   No Holiday   \n",
       "1            8.106    A  151315     6  2010            4.0   No Holiday   \n",
       "2            8.106    A  151315     7  2010            4.0   No Holiday   \n",
       "3            8.106    A  151315     8  2010            8.0   No Holiday   \n",
       "4            8.106    A  151315     9  2010            8.0   No Holiday   \n",
       "...            ...  ...     ...   ...   ...            ...          ...   \n",
       "6434         8.684    B  118221    39  2012           18.0   No Holiday   \n",
       "6435         8.667    B  118221    40  2012           18.0   No Holiday   \n",
       "6436         8.667    B  118221    41  2012           12.0   No Holiday   \n",
       "6437         8.667    B  118221    42  2012           14.0   No Holiday   \n",
       "6438         8.667    B  118221    43  2012           15.0   No Holiday   \n",
       "\n",
       "      Weekly_Sales     Ave_Sales  Ave_Fuel   Ave_Temp  Ave_Unem     Ave_CPI  \n",
       "0       1643690.90  1.555264e+06  3.219790  20.167832  7.610420  215.996891  \n",
       "1       1641957.44  1.555264e+06  3.219790  20.167832  7.610420  215.996891  \n",
       "2       1611968.17  1.555264e+06  3.219790  20.167832  7.610420  215.996891  \n",
       "3       1409727.59  1.555264e+06  3.219790  20.167832  7.610420  215.996891  \n",
       "4       1554806.68  1.555264e+06  3.219790  20.167832  7.610420  215.996891  \n",
       "...            ...           ...       ...        ...       ...         ...  \n",
       "6434     713173.95  7.859814e+05  3.417343  14.342657  8.648748  186.285678  \n",
       "6435     733455.07  7.859814e+05  3.417343  14.342657  8.648748  186.285678  \n",
       "6436     734464.36  7.859814e+05  3.417343  14.342657  8.648748  186.285678  \n",
       "6437     718125.53  7.859814e+05  3.417343  14.342657  8.648748  186.285678  \n",
       "6438     760281.43  7.859814e+05  3.417343  14.342657  8.648748  186.285678  \n",
       "\n",
       "[6439 rows x 20 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(walmart)):\n",
    "    walmart.loc[i, \"Ave_Sales\"] = totalave[walmart.loc[i, \"Store\"]]\n",
    "    walmart.loc[i, \"Ave_Fuel\"] = fuelave[walmart.loc[i, \"Store\"]]\n",
    "    walmart.loc[i, \"Ave_Temp\"] = tempave[walmart.loc[i, \"Store\"]]\n",
    "    walmart.loc[i, \"Ave_Unem\"] = unemave[walmart.loc[i, \"Store\"]]\n",
    "    walmart.loc[i, \"Ave_CPI\"] = cpiave[walmart.loc[i, \"Store\"]]\n",
    "walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Store</th>\n",
       "      <th>Start_of_Week</th>\n",
       "      <th>Week_Date</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>...</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Ave_Sales</th>\n",
       "      <th>Ave_Fuel</th>\n",
       "      <th>Ave_Temp</th>\n",
       "      <th>Ave_Unem</th>\n",
       "      <th>Ave_CPI</th>\n",
       "      <th>Fuel_Diff</th>\n",
       "      <th>Temp_Diff</th>\n",
       "      <th>Unem_Diff</th>\n",
       "      <th>CPI_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-30</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2.57</td>\n",
       "      <td>211.0964</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>...</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>-0.649790</td>\n",
       "      <td>-14.167832</td>\n",
       "      <td>0.495580</td>\n",
       "      <td>-4.900491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>2.55</td>\n",
       "      <td>211.2422</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>...</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>-0.669790</td>\n",
       "      <td>-16.167832</td>\n",
       "      <td>0.495580</td>\n",
       "      <td>-4.754691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>2.51</td>\n",
       "      <td>211.2891</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>...</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>-0.709790</td>\n",
       "      <td>-16.167832</td>\n",
       "      <td>0.495580</td>\n",
       "      <td>-4.707791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-20</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>2.56</td>\n",
       "      <td>211.3196</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>...</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>-0.659790</td>\n",
       "      <td>-12.167832</td>\n",
       "      <td>0.495580</td>\n",
       "      <td>-4.677291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>2.62</td>\n",
       "      <td>211.3501</td>\n",
       "      <td>8.106</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>...</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>1.555264e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>-0.599790</td>\n",
       "      <td>-12.167832</td>\n",
       "      <td>0.495580</td>\n",
       "      <td>-4.646791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>6434</td>\n",
       "      <td>6434</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-09-22</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>4.00</td>\n",
       "      <td>192.0136</td>\n",
       "      <td>8.684</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>...</td>\n",
       "      <td>713173.95</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>0.582657</td>\n",
       "      <td>3.657343</td>\n",
       "      <td>0.035252</td>\n",
       "      <td>5.727922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>6435</td>\n",
       "      <td>6435</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-09-29</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>3.98</td>\n",
       "      <td>192.1704</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>...</td>\n",
       "      <td>733455.07</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>0.562657</td>\n",
       "      <td>3.657343</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>5.884722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>6436</td>\n",
       "      <td>6436</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-06</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>4.00</td>\n",
       "      <td>192.3273</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>...</td>\n",
       "      <td>734464.36</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>0.582657</td>\n",
       "      <td>-2.342657</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>6.041622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6437</th>\n",
       "      <td>6437</td>\n",
       "      <td>6437</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-13</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>3.97</td>\n",
       "      <td>192.3309</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>...</td>\n",
       "      <td>718125.53</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>0.552657</td>\n",
       "      <td>-0.342657</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>6.045222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>6438</td>\n",
       "      <td>6438</td>\n",
       "      <td>45</td>\n",
       "      <td>2012-10-20</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>3.88</td>\n",
       "      <td>192.3089</td>\n",
       "      <td>8.667</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "      <td>...</td>\n",
       "      <td>760281.43</td>\n",
       "      <td>7.859814e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>0.462657</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>6.023222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6439 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    ID  Store Start_of_Week   Week_Date  Fuel_Price       CPI  \\\n",
       "0              0     0      1    2010-01-30  2010-02-05        2.57  211.0964   \n",
       "1              1     1      1    2010-02-06  2010-02-12        2.55  211.2422   \n",
       "2              2     2      1    2010-02-13  2010-02-19        2.51  211.2891   \n",
       "3              3     3      1    2010-02-20  2010-02-26        2.56  211.3196   \n",
       "4              4     4      1    2010-02-27  2010-03-05        2.62  211.3501   \n",
       "...          ...   ...    ...           ...         ...         ...       ...   \n",
       "6434        6434  6434     45    2012-09-22  2012-09-28        4.00  192.0136   \n",
       "6435        6435  6435     45    2012-09-29  2012-10-05        3.98  192.1704   \n",
       "6436        6436  6436     45    2012-10-06  2012-10-12        4.00  192.3273   \n",
       "6437        6437  6437     45    2012-10-13  2012-10-19        3.97  192.3309   \n",
       "6438        6438  6438     45    2012-10-20  2012-10-26        3.88  192.3089   \n",
       "\n",
       "      Unemployment Type    Size  ...  Weekly_Sales     Ave_Sales  Ave_Fuel  \\\n",
       "0            8.106    A  151315  ...    1643690.90  1.555264e+06  3.219790   \n",
       "1            8.106    A  151315  ...    1641957.44  1.555264e+06  3.219790   \n",
       "2            8.106    A  151315  ...    1611968.17  1.555264e+06  3.219790   \n",
       "3            8.106    A  151315  ...    1409727.59  1.555264e+06  3.219790   \n",
       "4            8.106    A  151315  ...    1554806.68  1.555264e+06  3.219790   \n",
       "...            ...  ...     ...  ...           ...           ...       ...   \n",
       "6434         8.684    B  118221  ...     713173.95  7.859814e+05  3.417343   \n",
       "6435         8.667    B  118221  ...     733455.07  7.859814e+05  3.417343   \n",
       "6436         8.667    B  118221  ...     734464.36  7.859814e+05  3.417343   \n",
       "6437         8.667    B  118221  ...     718125.53  7.859814e+05  3.417343   \n",
       "6438         8.667    B  118221  ...     760281.43  7.859814e+05  3.417343   \n",
       "\n",
       "       Ave_Temp  Ave_Unem     Ave_CPI  Fuel_Diff  Temp_Diff  Unem_Diff  \\\n",
       "0     20.167832  7.610420  215.996891  -0.649790 -14.167832   0.495580   \n",
       "1     20.167832  7.610420  215.996891  -0.669790 -16.167832   0.495580   \n",
       "2     20.167832  7.610420  215.996891  -0.709790 -16.167832   0.495580   \n",
       "3     20.167832  7.610420  215.996891  -0.659790 -12.167832   0.495580   \n",
       "4     20.167832  7.610420  215.996891  -0.599790 -12.167832   0.495580   \n",
       "...         ...       ...         ...        ...        ...        ...   \n",
       "6434  14.342657  8.648748  186.285678   0.582657   3.657343   0.035252   \n",
       "6435  14.342657  8.648748  186.285678   0.562657   3.657343   0.018252   \n",
       "6436  14.342657  8.648748  186.285678   0.582657  -2.342657   0.018252   \n",
       "6437  14.342657  8.648748  186.285678   0.552657  -0.342657   0.018252   \n",
       "6438  14.342657  8.648748  186.285678   0.462657   0.657343   0.018252   \n",
       "\n",
       "      CPI_Diff  \n",
       "0    -4.900491  \n",
       "1    -4.754691  \n",
       "2    -4.707791  \n",
       "3    -4.677291  \n",
       "4    -4.646791  \n",
       "...        ...  \n",
       "6434  5.727922  \n",
       "6435  5.884722  \n",
       "6436  6.041622  \n",
       "6437  6.045222  \n",
       "6438  6.023222  \n",
       "\n",
       "[6439 rows x 24 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart['Fuel_Diff'] = (walmart['Fuel_Price'] - walmart[\"Ave_Fuel\"])\n",
    "walmart['Temp_Diff'] = (walmart['Temperature_C'] - walmart[\"Ave_Temp\"])\n",
    "walmart['Unem_Diff'] = (walmart['Unemployment'] - walmart[\"Ave_Unem\"])\n",
    "walmart['CPI_Diff'] = (walmart['CPI'] - walmart[\"Ave_CPI\"])\n",
    "walmart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = walmart.filter(items=['Fuel_Diff', \"CPI_Diff\", \"Unem_Diff\", \"Temp_Diff\", \"Weekly_Sales\",\"Ave_Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#walmart = walmart.filter(items=['Fuel_Price', \"CPI\", \"Unemployment\", \"Temperature_C\", \"Weekly_Sales\",\"Ave_Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart.loc[walmart['Weekly_Sales'] > (1.15 * walmart[\"Ave_Sales\"]), 'Label'] = 'Above' \n",
    "walmart.loc[walmart['Weekly_Sales'] < (1.15 * walmart[\"Ave_Sales\"]), 'Label'] = 'Average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#walmart = walmart.filter(items=['Fuel_Price', \"CPI\", \"Unemployment\", \"Temperature_C\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = walmart.filter(items=['Fuel_Diff', \"CPI_Diff\", \"Unem_Diff\", \"Temp_Diff\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    5939\n",
       "Above       500\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6439, 4) (6439,)\n"
     ]
    }
   ],
   "source": [
    "X = walmart.drop(\"Label\", axis=1)\n",
    "y = walmart[\"Label\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "# Scale and train x value datasets\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9242079105404846\n",
      "Testing Data Score: 0.9167701863354037\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'solver': ['newton-cg', 'liblinear', 'sag', 'saga'],\n",
    "             'max_iter':[200, 500, 1000]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=1, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=1, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=1, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=1, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=1, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=1, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=1, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=1, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=1, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=200, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=newton-cg .............................\n",
      "[CV] . C=5, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=liblinear .............................\n",
      "[CV] . C=5, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=sag ...................................\n",
      "[CV] ....... C=5, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=500, solver=saga ..................................\n",
      "[CV] ...... C=5, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=newton-cg ............................\n",
      "[CV]  C=5, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=liblinear ............................\n",
      "[CV]  C=5, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=sag ..................................\n",
      "[CV] ...... C=5, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=5, max_iter=1000, solver=saga .................................\n",
      "[CV] ..... C=5, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=10, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=10, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=10, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=10, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=10, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=10, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=10, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=10, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=200, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=200, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=200, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=200, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=200, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n",
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=newton-cg ............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=50, max_iter=500, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=liblinear ............................\n",
      "[CV]  C=50, max_iter=500, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=sag ..................................\n",
      "[CV] ...... C=50, max_iter=500, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=500, solver=saga .................................\n",
      "[CV] ..... C=50, max_iter=500, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=newton-cg ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=newton-cg, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=liblinear ...........................\n",
      "[CV]  C=50, max_iter=1000, solver=liblinear, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=sag .................................\n",
      "[CV] ..... C=50, max_iter=1000, solver=sag, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.923, total=   0.0s\n",
      "[CV] C=50, max_iter=1000, solver=saga ................................\n",
      "[CV] .... C=50, max_iter=1000, solver=saga, score=0.924, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [1, 5, 10, 50], 'max_iter': [200, 500, 1000],\n",
       "                         'solver': ['newton-cg', 'liblinear', 'sag', 'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'max_iter': 200, 'solver': 'newton-cg'}\n",
      "0.9242079404413264\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9242079105404846\n",
      "Testing Data Score: 0.9167701863354037\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, max_iter=200, solver= 'newton-cg', random_state=42)\n",
    "logreg.fit(X_train_scaled, encoded_y_train)\n",
    "print(f\"Training Data Score: {logreg.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {logreg.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = walmart[\"Label\"]\n",
    "target_names = [\"Above\", \"Average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416149068322981"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf = rf.fit(X_train_scaled, encoded_y_train)\n",
    "rf.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.31428930901638674, 'Fuel_Diff'),\n",
       " (0.27238102371654105, 'CPI_Diff'),\n",
       " (0.24269665501712653, 'Temp_Diff'),\n",
       " (0.17063301224994573, 'Unem_Diff')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = walmart.columns\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "             'class_weight': ['None', 'balanced']}\n",
    "grid = GridSearchCV(rf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] class_weight=None, criterion=gini ...............................\n",
      "[CV] ..... class_weight=None, criterion=gini, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini ...............................\n",
      "[CV] ..... class_weight=None, criterion=gini, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini ...............................\n",
      "[CV] ..... class_weight=None, criterion=gini, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini ...............................\n",
      "[CV] ..... class_weight=None, criterion=gini, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini ...............................\n",
      "[CV] ..... class_weight=None, criterion=gini, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy ............................\n",
      "[CV] .. class_weight=None, criterion=entropy, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy ............................\n",
      "[CV] .. class_weight=None, criterion=entropy, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy ............................\n",
      "[CV] .. class_weight=None, criterion=entropy, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy ............................\n",
      "[CV] .. class_weight=None, criterion=entropy, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy ............................\n",
      "[CV] .. class_weight=None, criterion=entropy, score=nan, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  class_weight=balanced, criterion=gini, score=0.941, total=   4.2s\n",
      "[CV] class_weight=balanced, criterion=gini ...........................\n",
      "[CV]  class_weight=balanced, criterion=gini, score=0.943, total=   4.1s\n",
      "[CV] class_weight=balanced, criterion=gini ...........................\n",
      "[CV]  class_weight=balanced, criterion=gini, score=0.937, total=   4.2s\n",
      "[CV] class_weight=balanced, criterion=gini ...........................\n",
      "[CV]  class_weight=balanced, criterion=gini, score=0.938, total=   4.0s\n",
      "[CV] class_weight=balanced, criterion=gini ...........................\n",
      "[CV]  class_weight=balanced, criterion=gini, score=0.935, total=   4.0s\n",
      "[CV] class_weight=balanced, criterion=entropy ........................\n",
      "[CV]  class_weight=balanced, criterion=entropy, score=0.938, total=   4.7s\n",
      "[CV] class_weight=balanced, criterion=entropy ........................\n",
      "[CV]  class_weight=balanced, criterion=entropy, score=0.944, total=   4.7s\n",
      "[CV] class_weight=balanced, criterion=entropy ........................\n",
      "[CV]  class_weight=balanced, criterion=entropy, score=0.938, total=   4.6s\n",
      "[CV] class_weight=balanced, criterion=entropy ........................\n",
      "[CV]  class_weight=balanced, criterion=entropy, score=0.938, total=   4.6s\n",
      "[CV] class_weight=balanced, criterion=entropy ........................\n",
      "[CV]  class_weight=balanced, criterion=entropy, score=0.936, total=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   44.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_estimators=1000,\n",
       "                                              random_state=42),\n",
       "             param_grid={'class_weight': ['None', 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'entropy'}\n",
      "0.9387030540984135\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416149068322981"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "ranfor = ranfor.fit(X_train_scaled, encoded_y_train)\n",
    "ranfor.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260869565217391"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf = clf.fit(X_train_scaled, encoded_y_train)\n",
    "clf.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.33766648404249905, 'CPI_Diff'),\n",
       " (0.27584580572207335, 'Fuel_Diff'),\n",
       " (0.2374634880509487, 'Temp_Diff'),\n",
       " (0.14902422218447894, 'Unem_Diff')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = walmart.columns\n",
    "sorted(zip(clf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'splitter': ['best', 'random'],\n",
    "             'class_weight': ['None', 'balanced']}\n",
    "grid = GridSearchCV(clf, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=best ................\n",
      "[CV]  class_weight=None, criterion=gini, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=gini, splitter=random ..............\n",
      "[CV]  class_weight=None, criterion=gini, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=best .............\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=best, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=None, criterion=entropy, splitter=random ...........\n",
      "[CV]  class_weight=None, criterion=entropy, splitter=random, score=nan, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.921, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.931, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.911, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.919, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=best ............\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=best, score=0.916, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.895, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.924, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.912, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.922, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=gini, splitter=random ..........\n",
      "[CV]  class_weight=balanced, criterion=gini, splitter=random, score=0.915, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.917, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.928, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.903, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.925, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=best .........\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=best, score=0.918, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.911, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.927, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.914, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n",
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.930, total=   0.0s\n",
      "[CV] class_weight=balanced, criterion=entropy, splitter=random .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/ronaldclarke/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  class_weight=balanced, criterion=entropy, splitter=random, score=0.913, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'class_weight': ['None', 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'criterion': 'gini', 'splitter': 'best'}\n",
      "0.9196513586286057\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260869565217391"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre = tree.DecisionTreeClassifier(random_state=42)\n",
    "dectre = dectre.fit(X_train_scaled, encoded_y_train)\n",
    "dectre.score(X_test_scaled, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectre_predictions = dectre.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranfor_predictions = ranfor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Above       0.74      0.46      0.57       134\n",
      "     Average       0.95      0.99      0.97      1476\n",
      "\n",
      "    accuracy                           0.94      1610\n",
      "   macro avg       0.85      0.72      0.77      1610\n",
      "weighted avg       0.93      0.94      0.94      1610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(encoded_y_test, ranfor_predictions,\n",
    "                            target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Above       0.56      0.54      0.55       134\n",
      "     Average       0.96      0.96      0.96      1476\n",
      "\n",
      "    accuracy                           0.93      1610\n",
      "   macro avg       0.76      0.75      0.75      1610\n",
      "weighted avg       0.92      0.93      0.93      1610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(encoded_y_test, dectre_predictions,\n",
    "                            target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0  2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1  2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2  2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3  2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4  2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "\n",
       "   Weekly_Sales  \n",
       "0  1.529256e+06  \n",
       "1  1.587566e+06  \n",
       "2  1.678286e+06  \n",
       "3  1.742059e+06  \n",
       "4  1.765627e+06  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predix = pd.read_csv('prophet_predictions.csv')\n",
    "predix = predix.drop(['Unnamed: 0'], axis=1)\n",
    "predix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Ave_Fuel</th>\n",
       "      <th>Ave_CPI</th>\n",
       "      <th>Ave_Temp</th>\n",
       "      <th>Ave_Unem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0     2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1     2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2     2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3     2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4     2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "...          ...    ...         ...         ...           ...            ...   \n",
       "2470  2013-10-06     45    4.393188  195.136141      8.878137      16.570370   \n",
       "2471  2013-10-13     45    4.400800  195.177228      8.872678      15.371153   \n",
       "2472  2013-10-20     45    4.394871  195.161653      8.877326      13.409695   \n",
       "2473  2013-10-27     45    4.380892  195.115184      8.887845      11.328064   \n",
       "2474  2013-11-03     45    4.374071  195.052613      8.895672      10.263839   \n",
       "\n",
       "      Weekly_Sales  Ave_Fuel     Ave_CPI   Ave_Temp  Ave_Unem  \n",
       "0     1.529256e+06  3.219790  215.996891  20.167832  7.610420  \n",
       "1     1.587566e+06  3.219790  215.996891  20.167832  7.610420  \n",
       "2     1.678286e+06  3.219790  215.996891  20.167832  7.610420  \n",
       "3     1.742059e+06  3.219790  215.996891  20.167832  7.610420  \n",
       "4     1.765627e+06  3.219790  215.996891  20.167832  7.610420  \n",
       "...            ...       ...         ...        ...       ...  \n",
       "2470  7.524903e+05  3.417343  186.285678  14.342657  8.648748  \n",
       "2471  7.420480e+05  3.417343  186.285678  14.342657  8.648748  \n",
       "2472  7.451909e+05  3.417343  186.285678  14.342657  8.648748  \n",
       "2473  7.835365e+05  3.417343  186.285678  14.342657  8.648748  \n",
       "2474  8.378446e+05  3.417343  186.285678  14.342657  8.648748  \n",
       "\n",
       "[2475 rows x 11 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(predix)):\n",
    "    predix.loc[i, \"Ave_Fuel\"] = fuelave[predix.loc[i, \"Store\"]]\n",
    "    predix.loc[i, \"Ave_CPI\"] = cpiave[predix.loc[i, \"Store\"]]\n",
    "    predix.loc[i, \"Ave_Temp\"] = tempave[predix.loc[i, \"Store\"]]\n",
    "    predix.loc[i, \"Ave_Unem\"] = unemave[predix.loc[i, \"Store\"]]\n",
    "predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Ave_Fuel</th>\n",
       "      <th>Ave_CPI</th>\n",
       "      <th>Ave_Temp</th>\n",
       "      <th>Ave_Unem</th>\n",
       "      <th>Fuel_Diff</th>\n",
       "      <th>Temp_Diff</th>\n",
       "      <th>Unem_Diff</th>\n",
       "      <th>CPI_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.487440</td>\n",
       "      <td>223.461145</td>\n",
       "      <td>6.627970</td>\n",
       "      <td>17.659895</td>\n",
       "      <td>1.529256e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>0.267649</td>\n",
       "      <td>-2.507938</td>\n",
       "      <td>-0.982450</td>\n",
       "      <td>7.464254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>3.472333</td>\n",
       "      <td>223.443172</td>\n",
       "      <td>6.634452</td>\n",
       "      <td>16.448992</td>\n",
       "      <td>1.587566e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>0.252542</td>\n",
       "      <td>-3.718840</td>\n",
       "      <td>-0.975968</td>\n",
       "      <td>7.446281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3.456623</td>\n",
       "      <td>223.409742</td>\n",
       "      <td>6.623966</td>\n",
       "      <td>15.104578</td>\n",
       "      <td>1.678286e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>0.236833</td>\n",
       "      <td>-5.063254</td>\n",
       "      <td>-0.986453</td>\n",
       "      <td>7.412851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.441573</td>\n",
       "      <td>223.372609</td>\n",
       "      <td>6.592424</td>\n",
       "      <td>13.620766</td>\n",
       "      <td>1.742059e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>0.221783</td>\n",
       "      <td>-6.547066</td>\n",
       "      <td>-1.017996</td>\n",
       "      <td>7.375718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.423539</td>\n",
       "      <td>223.358492</td>\n",
       "      <td>6.556789</td>\n",
       "      <td>12.028795</td>\n",
       "      <td>1.765627e+06</td>\n",
       "      <td>3.219790</td>\n",
       "      <td>215.996891</td>\n",
       "      <td>20.167832</td>\n",
       "      <td>7.610420</td>\n",
       "      <td>0.203749</td>\n",
       "      <td>-8.139037</td>\n",
       "      <td>-1.053631</td>\n",
       "      <td>7.361601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>4.393188</td>\n",
       "      <td>195.136141</td>\n",
       "      <td>8.878137</td>\n",
       "      <td>16.570370</td>\n",
       "      <td>7.524903e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>0.975846</td>\n",
       "      <td>2.227712</td>\n",
       "      <td>0.229388</td>\n",
       "      <td>8.850462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>4.400800</td>\n",
       "      <td>195.177228</td>\n",
       "      <td>8.872678</td>\n",
       "      <td>15.371153</td>\n",
       "      <td>7.420480e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>0.983458</td>\n",
       "      <td>1.028496</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>8.891549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.394871</td>\n",
       "      <td>195.161653</td>\n",
       "      <td>8.877326</td>\n",
       "      <td>13.409695</td>\n",
       "      <td>7.451909e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>0.977529</td>\n",
       "      <td>-0.932962</td>\n",
       "      <td>0.228578</td>\n",
       "      <td>8.875975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>4.380892</td>\n",
       "      <td>195.115184</td>\n",
       "      <td>8.887845</td>\n",
       "      <td>11.328064</td>\n",
       "      <td>7.835365e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>0.963550</td>\n",
       "      <td>-3.014594</td>\n",
       "      <td>0.239096</td>\n",
       "      <td>8.829505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>4.374071</td>\n",
       "      <td>195.052613</td>\n",
       "      <td>8.895672</td>\n",
       "      <td>10.263839</td>\n",
       "      <td>8.378446e+05</td>\n",
       "      <td>3.417343</td>\n",
       "      <td>186.285678</td>\n",
       "      <td>14.342657</td>\n",
       "      <td>8.648748</td>\n",
       "      <td>0.956728</td>\n",
       "      <td>-4.078819</td>\n",
       "      <td>0.246924</td>\n",
       "      <td>8.766935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Price         CPI  Unemployment  Temperature_C  \\\n",
       "0     2012-10-21      1    3.487440  223.461145      6.627970      17.659895   \n",
       "1     2012-10-28      1    3.472333  223.443172      6.634452      16.448992   \n",
       "2     2012-11-04      1    3.456623  223.409742      6.623966      15.104578   \n",
       "3     2012-11-11      1    3.441573  223.372609      6.592424      13.620766   \n",
       "4     2012-11-18      1    3.423539  223.358492      6.556789      12.028795   \n",
       "...          ...    ...         ...         ...           ...            ...   \n",
       "2470  2013-10-06     45    4.393188  195.136141      8.878137      16.570370   \n",
       "2471  2013-10-13     45    4.400800  195.177228      8.872678      15.371153   \n",
       "2472  2013-10-20     45    4.394871  195.161653      8.877326      13.409695   \n",
       "2473  2013-10-27     45    4.380892  195.115184      8.887845      11.328064   \n",
       "2474  2013-11-03     45    4.374071  195.052613      8.895672      10.263839   \n",
       "\n",
       "      Weekly_Sales  Ave_Fuel     Ave_CPI   Ave_Temp  Ave_Unem  Fuel_Diff  \\\n",
       "0     1.529256e+06  3.219790  215.996891  20.167832  7.610420   0.267649   \n",
       "1     1.587566e+06  3.219790  215.996891  20.167832  7.610420   0.252542   \n",
       "2     1.678286e+06  3.219790  215.996891  20.167832  7.610420   0.236833   \n",
       "3     1.742059e+06  3.219790  215.996891  20.167832  7.610420   0.221783   \n",
       "4     1.765627e+06  3.219790  215.996891  20.167832  7.610420   0.203749   \n",
       "...            ...       ...         ...        ...       ...        ...   \n",
       "2470  7.524903e+05  3.417343  186.285678  14.342657  8.648748   0.975846   \n",
       "2471  7.420480e+05  3.417343  186.285678  14.342657  8.648748   0.983458   \n",
       "2472  7.451909e+05  3.417343  186.285678  14.342657  8.648748   0.977529   \n",
       "2473  7.835365e+05  3.417343  186.285678  14.342657  8.648748   0.963550   \n",
       "2474  8.378446e+05  3.417343  186.285678  14.342657  8.648748   0.956728   \n",
       "\n",
       "      Temp_Diff  Unem_Diff  CPI_Diff  \n",
       "0     -2.507938  -0.982450  7.464254  \n",
       "1     -3.718840  -0.975968  7.446281  \n",
       "2     -5.063254  -0.986453  7.412851  \n",
       "3     -6.547066  -1.017996  7.375718  \n",
       "4     -8.139037  -1.053631  7.361601  \n",
       "...         ...        ...       ...  \n",
       "2470   2.227712   0.229388  8.850462  \n",
       "2471   1.028496   0.223930  8.891549  \n",
       "2472  -0.932962   0.228578  8.875975  \n",
       "2473  -3.014594   0.239096  8.829505  \n",
       "2474  -4.078819   0.246924  8.766935  \n",
       "\n",
       "[2475 rows x 15 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predix['Fuel_Diff'] = (predix['Fuel_Price'] - predix[\"Ave_Fuel\"])\n",
    "predix['Temp_Diff'] = (predix['Temperature_C'] - predix[\"Ave_Temp\"])\n",
    "predix['Unem_Diff'] = (predix['Unemployment'] - predix[\"Ave_Unem\"])\n",
    "predix['CPI_Diff'] = (predix['CPI'] - predix[\"Ave_CPI\"])\n",
    "predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predix = predix.filter(items=['Date', 'Store', 'Fuel_Diff', \"CPI_Diff\", \"Unem_Diff\", \"Temp_Diff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fuel_Diff</th>\n",
       "      <th>CPI_Diff</th>\n",
       "      <th>Unem_Diff</th>\n",
       "      <th>Temp_Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267649</td>\n",
       "      <td>7.464254</td>\n",
       "      <td>-0.982450</td>\n",
       "      <td>-2.507938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.252542</td>\n",
       "      <td>7.446281</td>\n",
       "      <td>-0.975968</td>\n",
       "      <td>-3.718840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236833</td>\n",
       "      <td>7.412851</td>\n",
       "      <td>-0.986453</td>\n",
       "      <td>-5.063254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221783</td>\n",
       "      <td>7.375718</td>\n",
       "      <td>-1.017996</td>\n",
       "      <td>-6.547066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203749</td>\n",
       "      <td>7.361601</td>\n",
       "      <td>-1.053631</td>\n",
       "      <td>-8.139037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>0.975846</td>\n",
       "      <td>8.850462</td>\n",
       "      <td>0.229388</td>\n",
       "      <td>2.227712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>0.983458</td>\n",
       "      <td>8.891549</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>1.028496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>0.977529</td>\n",
       "      <td>8.875975</td>\n",
       "      <td>0.228578</td>\n",
       "      <td>-0.932962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>0.963550</td>\n",
       "      <td>8.829505</td>\n",
       "      <td>0.239096</td>\n",
       "      <td>-3.014594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>0.956728</td>\n",
       "      <td>8.766935</td>\n",
       "      <td>0.246924</td>\n",
       "      <td>-4.078819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fuel_Diff  CPI_Diff  Unem_Diff  Temp_Diff\n",
       "0      0.267649  7.464254  -0.982450  -2.507938\n",
       "1      0.252542  7.446281  -0.975968  -3.718840\n",
       "2      0.236833  7.412851  -0.986453  -5.063254\n",
       "3      0.221783  7.375718  -1.017996  -6.547066\n",
       "4      0.203749  7.361601  -1.053631  -8.139037\n",
       "...         ...       ...        ...        ...\n",
       "2470   0.975846  8.850462   0.229388   2.227712\n",
       "2471   0.983458  8.891549   0.223930   1.028496\n",
       "2472   0.977529  8.875975   0.228578  -0.932962\n",
       "2473   0.963550  8.829505   0.239096  -3.014594\n",
       "2474   0.956728  8.766935   0.246924  -4.078819\n",
       "\n",
       "[2475 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predix\n",
    "X = predix.drop(\"Date\", axis=1)\n",
    "X = X.drop(\"Store\", axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predix_scaled = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranfor_labels = rf.predict(predix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Average', 'Average', 'Average', ..., 'Average', 'Average',\n",
       "       'Average'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_labels = label_encoder.inverse_transform(ranfor_labels)\n",
    "ranfor_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Diff</th>\n",
       "      <th>CPI_Diff</th>\n",
       "      <th>Unem_Diff</th>\n",
       "      <th>Temp_Diff</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267649</td>\n",
       "      <td>7.464254</td>\n",
       "      <td>-0.982450</td>\n",
       "      <td>-2.507938</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252542</td>\n",
       "      <td>7.446281</td>\n",
       "      <td>-0.975968</td>\n",
       "      <td>-3.718840</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236833</td>\n",
       "      <td>7.412851</td>\n",
       "      <td>-0.986453</td>\n",
       "      <td>-5.063254</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221783</td>\n",
       "      <td>7.375718</td>\n",
       "      <td>-1.017996</td>\n",
       "      <td>-6.547066</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203749</td>\n",
       "      <td>7.361601</td>\n",
       "      <td>-1.053631</td>\n",
       "      <td>-8.139037</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>0.975846</td>\n",
       "      <td>8.850462</td>\n",
       "      <td>0.229388</td>\n",
       "      <td>2.227712</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>0.983458</td>\n",
       "      <td>8.891549</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>1.028496</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>0.977529</td>\n",
       "      <td>8.875975</td>\n",
       "      <td>0.228578</td>\n",
       "      <td>-0.932962</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>0.963550</td>\n",
       "      <td>8.829505</td>\n",
       "      <td>0.239096</td>\n",
       "      <td>-3.014594</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>0.956728</td>\n",
       "      <td>8.766935</td>\n",
       "      <td>0.246924</td>\n",
       "      <td>-4.078819</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Diff  CPI_Diff  Unem_Diff  Temp_Diff    Label\n",
       "0     2012-10-21      1   0.267649  7.464254  -0.982450  -2.507938  Average\n",
       "1     2012-10-28      1   0.252542  7.446281  -0.975968  -3.718840  Average\n",
       "2     2012-11-04      1   0.236833  7.412851  -0.986453  -5.063254  Average\n",
       "3     2012-11-11      1   0.221783  7.375718  -1.017996  -6.547066  Average\n",
       "4     2012-11-18      1   0.203749  7.361601  -1.053631  -8.139037  Average\n",
       "...          ...    ...        ...       ...        ...        ...      ...\n",
       "2470  2013-10-06     45   0.975846  8.850462   0.229388   2.227712  Average\n",
       "2471  2013-10-13     45   0.983458  8.891549   0.223930   1.028496  Average\n",
       "2472  2013-10-20     45   0.977529  8.875975   0.228578  -0.932962  Average\n",
       "2473  2013-10-27     45   0.963550  8.829505   0.239096  -3.014594  Average\n",
       "2474  2013-11-03     45   0.956728  8.766935   0.246924  -4.078819  Average\n",
       "\n",
       "[2475 rows x 7 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_predix = predix\n",
    "ranfor_predix[\"Label\"] = ranfor_labels\n",
    "ranfor_predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2475\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectre_labels = dectre.predict(predix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Average', 'Average', 'Above', ..., 'Average', 'Average',\n",
       "       'Average'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_labels = label_encoder.inverse_transform(dectre_labels)\n",
    "dectre_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>Fuel_Diff</th>\n",
       "      <th>CPI_Diff</th>\n",
       "      <th>Unem_Diff</th>\n",
       "      <th>Temp_Diff</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267649</td>\n",
       "      <td>7.464254</td>\n",
       "      <td>-0.982450</td>\n",
       "      <td>-2.507938</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.252542</td>\n",
       "      <td>7.446281</td>\n",
       "      <td>-0.975968</td>\n",
       "      <td>-3.718840</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236833</td>\n",
       "      <td>7.412851</td>\n",
       "      <td>-0.986453</td>\n",
       "      <td>-5.063254</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221783</td>\n",
       "      <td>7.375718</td>\n",
       "      <td>-1.017996</td>\n",
       "      <td>-6.547066</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203749</td>\n",
       "      <td>7.361601</td>\n",
       "      <td>-1.053631</td>\n",
       "      <td>-8.139037</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>45</td>\n",
       "      <td>0.975846</td>\n",
       "      <td>8.850462</td>\n",
       "      <td>0.229388</td>\n",
       "      <td>2.227712</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2013-10-13</td>\n",
       "      <td>45</td>\n",
       "      <td>0.983458</td>\n",
       "      <td>8.891549</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>1.028496</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2013-10-20</td>\n",
       "      <td>45</td>\n",
       "      <td>0.977529</td>\n",
       "      <td>8.875975</td>\n",
       "      <td>0.228578</td>\n",
       "      <td>-0.932962</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>45</td>\n",
       "      <td>0.963550</td>\n",
       "      <td>8.829505</td>\n",
       "      <td>0.239096</td>\n",
       "      <td>-3.014594</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2013-11-03</td>\n",
       "      <td>45</td>\n",
       "      <td>0.956728</td>\n",
       "      <td>8.766935</td>\n",
       "      <td>0.246924</td>\n",
       "      <td>-4.078819</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Store  Fuel_Diff  CPI_Diff  Unem_Diff  Temp_Diff    Label\n",
       "0     2012-10-21      1   0.267649  7.464254  -0.982450  -2.507938  Average\n",
       "1     2012-10-28      1   0.252542  7.446281  -0.975968  -3.718840  Average\n",
       "2     2012-11-04      1   0.236833  7.412851  -0.986453  -5.063254    Above\n",
       "3     2012-11-11      1   0.221783  7.375718  -1.017996  -6.547066    Above\n",
       "4     2012-11-18      1   0.203749  7.361601  -1.053631  -8.139037    Above\n",
       "...          ...    ...        ...       ...        ...        ...      ...\n",
       "2470  2013-10-06     45   0.975846  8.850462   0.229388   2.227712  Average\n",
       "2471  2013-10-13     45   0.983458  8.891549   0.223930   1.028496  Average\n",
       "2472  2013-10-20     45   0.977529  8.875975   0.228578  -0.932962  Average\n",
       "2473  2013-10-27     45   0.963550  8.829505   0.239096  -3.014594  Average\n",
       "2474  2013-11-03     45   0.956728  8.766935   0.246924  -4.078819  Average\n",
       "\n",
       "[2475 rows x 7 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_predix = predix\n",
    "dectre_predix[\"Label\"] = dectre_labels\n",
    "dectre_predix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2160\n",
       "Above       315\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dectre_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average    2475\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranfor_predix[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
